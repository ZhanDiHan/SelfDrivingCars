{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, ELU, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.backend import tf as ktf\n",
    "from keras.optimizers import Adam\n",
    "from scipy.misc import imresize\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import csv\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read csv generated from the driving simulator\n",
    "lines = []\n",
    "with open('./data/data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_path_from_to(path, from_path=\"IMG\",to_path=\"./data/data/IMG\"):\n",
    "    return path.replace(from_path, to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def flip_image_and_steering(img, steering):\n",
    "    return (np.fliplr(img), -steering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_img(img): \n",
    "    return imresize(img[35:135, :], (66, 208, 3), interp='bilinear', mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Thanks for Vivek Yadav and his work here, https://chatbotslife.com/using-augmentation-to-mimic-human-driving-496b569760a9\n",
    "# I was able to augment the data with more images using the following methods\n",
    "    \n",
    "#random brightness    \n",
    "def augment_brightness_camera_images(image):\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    image1 = np.array(image1, dtype = np.float64)\n",
    "    random_bright = .5+np.random.uniform()\n",
    "    image1[:,:,2] = image1[:,:,2]*random_bright\n",
    "    image1[:,:,2][image1[:,:,2]>255]  = 255\n",
    "    image1 = np.array(image1, dtype = np.uint8)\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1\n",
    "\n",
    "#random shiftts\n",
    "def trans_image(image,steer,trans_range):\n",
    "    # Translation\n",
    "    tr_x = trans_range*np.random.uniform()-trans_range/2\n",
    "    steer_ang = steer + tr_x/trans_range*2*.2\n",
    "    tr_y = 40*np.random.uniform()-40/2\n",
    "    #tr_y = 0\n",
    "    Trans_M = np.float32([[1,0,tr_x],[0,1,tr_y]])\n",
    "    image_tr = cv2.warpAffine(image,Trans_M,(cols,rows))\n",
    "    \n",
    "    return image_tr,steer_ang, tr_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us test the augment_brightness_camera_images on one of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread(change_path_from_to(lines[132][0].strip()))\n",
    "rows,cols,channels = image.shape\n",
    "steer = float(lines[132][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()\n",
    "plt.imshow(augment_brightness_camera_images(image))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_tr,steer_ang,tr_x = trans_image(image,steer,80)\n",
    "plt.imshow(image_tr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us look at some samples after we apply the random shifting for one of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.subplot(4,3,1)\n",
    "plt.imshow(image)\n",
    "plt.title('str: ' + str(np.round(steer,2)))\n",
    "plt.axis('off')\n",
    "\n",
    "for i in range(11):\n",
    "    plt.subplot(4,3,i+2)\n",
    "    image_tr,steer_ang,tr_x = trans_image(image,steer,50)\n",
    "    plt.title('str: ' + str(np.round(steer_ang,2)) )\n",
    "    plt.imshow(image_tr)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(imagepath):    \n",
    "    im = mpimg.imread(imagepath, 1)\n",
    "    return imresize(im[45:135, :], (66, 208, 3), interp='bilinear', mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#our X\n",
    "car_images = []\n",
    "\n",
    "#our Y - steering angle \n",
    "steering_angles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "flag = True\n",
    "\n",
    "for line in lines:\n",
    "    if i == 0:\n",
    "        i = i + 1\n",
    "        continue\n",
    "    \n",
    "    #get corresponding streeing angle to Y\n",
    "    steering_center = float(line[3])       \n",
    "    \n",
    "    # read in images from center, left and right cameras\n",
    "    img_center = load_image(change_path_from_to(line[0].strip()))\n",
    "    img_left = load_image(change_path_from_to(line[1].strip()))\n",
    "    img_right = load_image(change_path_from_to(line[2].strip()))    \n",
    "    \n",
    "#     # read in images from center, left and right cameras\n",
    "#     img_center = cv2.imread(change_path_from_to(line[0].strip()))\n",
    "#     img_left = cv2.imread(change_path_from_to(line[1].strip()))\n",
    "#     img_right = cv2.imread(change_path_from_to(line[2].strip()))\n",
    "\n",
    "   \n",
    "    # create adjusted steering measurements for the side camera images\n",
    "    correction = 0.20 # this is a parameter to tune\n",
    "    steering_left = steering_center + correction\n",
    "    steering_right = steering_center - correction    \n",
    "    \n",
    "   \n",
    "    #lets start augmenting data for these set of images\n",
    "\n",
    "    #flip the center , left and right images and add to the augmented list \n",
    "    img_center_flipped, steering_center_flipped = flip_image_and_steering(img_center, steering_center)\n",
    "    img_left_flipped, steering_left_flipped = flip_image_and_steering(img_left, steering_left)\n",
    "    img_right_flipped, steering_right_flipped = flip_image_and_steering(img_right, steering_right)\n",
    "    \n",
    "    \n",
    "    \n",
    "    aug_list_of_images = [img_center, img_left, img_right, img_center_flipped, img_left_flipped, img_right_flipped, \n",
    "                          augment_brightness_camera_images(img_center)]\n",
    "    \n",
    "    aug_list_of_steering_angles = [steering_center, steering_left, steering_right, \n",
    "                                   steering_center_flipped, steering_left_flipped, steering_right_flipped, steering_center]    \n",
    "    \n",
    "#     #lets augment some more data by using brightness adjustment and random shifting \n",
    "#     indx = randint(1,3)\n",
    "#     if indx == 1:\n",
    "#         img_to_change_and_append = img_center\n",
    "#         flipped_img_to_change_and_append = img_center_flipped\n",
    "#         steering_to_append = steering_center\n",
    "#     elif indx == 2:\n",
    "#         img_to_change_and_append = img_left\n",
    "#         flipped_img_to_change_and_append = img_left_flipped\n",
    "#         steering_to_append = steering_left\n",
    "#     else:\n",
    "#         img_to_change_and_append = img_right\n",
    "#         flipped_img_to_change_and_append = img_right_flipped\n",
    "#         steering_to_append = steering_right\n",
    "    \n",
    "\n",
    "#     #for the image, get a copy with some adjusted brightness\n",
    "#     aug_list_of_images.append(augment_brightness_camera_images(img_to_change_and_append))\n",
    "#     aug_list_of_steering_angles.append(steering_to_append)\n",
    "    \n",
    "#     #randomly shift the image and get the corresponding sheered image and adjusted steering angle \n",
    "#     image_tr,steer_ang,tr_x = trans_image(img_to_change_and_append,steering_to_append,80)\n",
    "#     aug_list_of_images.append(image_tr)\n",
    "#     aug_list_of_steering_angles.append(steer)\n",
    "    \n",
    "    \n",
    "#     #adjust the brightness for flipped image and add it to augmented list\n",
    "#     aug_list_of_images.append(augment_brightness_camera_images(flipped_img_to_change_and_append))\n",
    "#     aug_list_of_steering_angles.append(-steering_to_append)\n",
    "\n",
    "\n",
    "    #for the image, get a copy with some adjusted brightness\n",
    "#     aug_list_of_images.append(augment_brightness_camera_images(img_center))\n",
    "#     aug_list_of_steering_angles.append(steering_center)\n",
    "    \n",
    "#     aug_list_of_images.append(augment_brightness_camera_images(img_center))\n",
    "#     aug_list_of_steering_angles.append(steering_center)    \n",
    "    \n",
    "#     if flag:\n",
    "#         #for the image, get a copy with some adjusted brightness\n",
    "#         aug_list_of_images.append(augment_brightness_camera_images(img_left))\n",
    "#         aug_list_of_steering_angles.append(steering_left)\n",
    "#         flag = False\n",
    "#     else:\n",
    "#         #for the image, get a copy with some adjusted brightness\n",
    "#         aug_list_of_images.append(augment_brightness_camera_images(img_right))\n",
    "#         aug_list_of_steering_angles.append(steering_right)\n",
    "#         flag = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     aug_list_of_images.append(augment_brightness_camera_images(img_center))\n",
    "#     aug_list_of_steering_angles.append(steering_center) \n",
    "\n",
    "\n",
    "\n",
    "#     #randomly shift the image and get the corresponding sheered image and adjusted steering angle \n",
    "#     if flag:\n",
    "#         image_tr,steer_ang,tr_x = trans_image(img_center,steering_center,50)\n",
    "#         aug_list_of_images.append(image_tr)\n",
    "#         aug_list_of_steering_angles.append(steer)\n",
    "#         flag = False\n",
    "#     else:\n",
    "#         aug_list_of_images.append(augment_brightness_camera_images(img_center))\n",
    "#         aug_list_of_steering_angles.append(steering_center)    \n",
    "#         flag = True\n",
    "    \n",
    "#     #adjust the brightness for flipped image and add it to augmented list\n",
    "#     aug_list_of_images.append(augment_brightness_camera_images(img_center_flipped))\n",
    "#     aug_list_of_steering_angles.append(steering_center_flipped)\n",
    "\n",
    "\n",
    "\n",
    "    #finally add to the final list \n",
    "    car_images.extend(aug_list_of_images)\n",
    "    steering_angles.extend(aug_list_of_steering_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(car_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(steering_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# flag = True\n",
    "\n",
    "# for line in lines:\n",
    "#     if i == 0:\n",
    "#         i = i + 1\n",
    "#         continue\n",
    "    \n",
    "    \n",
    "#     probability = random.random()\n",
    "    \n",
    "#     #get corresponding streeing angle to Y\n",
    "#     steering_center = float(line[3])\n",
    "    \n",
    "#     #since majority of the data is biased towards steering at 0 angle, we need nullify the effect of this bias\n",
    "#     #we half of the straight steering images out so that we have a more balanced dataset\n",
    "# #     if (probability < 0.35 and abs(steering_center) < 0.001):\n",
    "# #         continue\n",
    "        \n",
    "        \n",
    "    \n",
    "#     # read in images from center, left and right cameras\n",
    "#     img_center = cv2.imread(change_path_from_to(line[0].strip()))\n",
    "#     img_left = cv2.imread(change_path_from_to(line[1].strip()))\n",
    "#     img_right = cv2.imread(change_path_from_to(line[2].strip()))\n",
    "\n",
    "\n",
    "    \n",
    "#     # create adjusted steering measurements for the side camera images\n",
    "#     correction = 0.25 # this is a parameter to tune\n",
    "#     steering_left = steering_center + correction\n",
    "#     steering_right = steering_center - correction    \n",
    "    \n",
    "#     aug_list_of_images = [img_center, img_left, img_right]\n",
    "#     aug_list_of_steering_angles = [steering_center, steering_left, steering_right]\n",
    "    \n",
    "#     #lets start augmenting data for these set of images\n",
    "\n",
    "#     #flip the center , left and right images and add to the augmented list \n",
    "#     img_center_flipped, steering_center_flipped = flip_image_and_steering(img_center, steering_center)\n",
    "#     img_left_flipped, steering_left_flipped = flip_image_and_steering(img_left, steering_left)\n",
    "#     img_right_flipped, steering_right_flipped = flip_image_and_steering(img_right, steering_right)\n",
    "    \n",
    "#     aug_list_of_images.append(img_center_flipped)\n",
    "#     aug_list_of_steering_angles.append(steering_center_flipped)\n",
    "\n",
    "#     aug_list_of_images.append(img_left_flipped)\n",
    "#     aug_list_of_steering_angles.append(steering_left_flipped)\n",
    "    \n",
    "#     aug_list_of_images.append(img_right_flipped)\n",
    "#     aug_list_of_steering_angles.append(steering_right_flipped)\n",
    "    \n",
    "    \n",
    "# #     #lets augment some more data by using brightness adjustment and random shifting \n",
    "# #     indx = randint(1,3)\n",
    "# #     if indx == 1:\n",
    "# #         img_to_change_and_append = img_center\n",
    "# #         flipped_img_to_change_and_append = img_center_flipped\n",
    "# #         steering_to_append = steering_center\n",
    "# #     elif indx == 2:\n",
    "# #         img_to_change_and_append = img_left\n",
    "# #         flipped_img_to_change_and_append = img_left_flipped\n",
    "# #         steering_to_append = steering_left\n",
    "# #     else:\n",
    "# #         img_to_change_and_append = img_right\n",
    "# #         flipped_img_to_change_and_append = img_right_flipped\n",
    "# #         steering_to_append = steering_right\n",
    "    \n",
    "\n",
    "# #     #for the image, get a copy with some adjusted brightness\n",
    "# #     aug_list_of_images.append(augment_brightness_camera_images(img_to_change_and_append))\n",
    "# #     aug_list_of_steering_angles.append(steering_to_append)\n",
    "    \n",
    "# #     #randomly shift the image and get the corresponding sheered image and adjusted steering angle \n",
    "# #     image_tr,steer_ang,tr_x = trans_image(img_to_change_and_append,steering_to_append,80)\n",
    "# #     aug_list_of_images.append(image_tr)\n",
    "# #     aug_list_of_steering_angles.append(steer)\n",
    "    \n",
    "    \n",
    "# #     #adjust the brightness for flipped image and add it to augmented list\n",
    "# #     aug_list_of_images.append(augment_brightness_camera_images(flipped_img_to_change_and_append))\n",
    "# #     aug_list_of_steering_angles.append(-steering_to_append)\n",
    "\n",
    "\n",
    "#     #for the image, get a copy with some adjusted brightness\n",
    "# #     aug_list_of_images.append(augment_brightness_camera_images(img_center))\n",
    "# #     aug_list_of_steering_angles.append(steering_center)\n",
    "    \n",
    "# #     aug_list_of_images.append(augment_brightness_camera_images(img_center))\n",
    "# #     aug_list_of_steering_angles.append(steering_center)    \n",
    "    \n",
    "# #     if flag:\n",
    "# #         #for the image, get a copy with some adjusted brightness\n",
    "# #         aug_list_of_images.append(augment_brightness_camera_images(img_left))\n",
    "# #         aug_list_of_steering_angles.append(steering_left)\n",
    "# #         flag = False\n",
    "# #     else:\n",
    "# #         #for the image, get a copy with some adjusted brightness\n",
    "# #         aug_list_of_images.append(augment_brightness_camera_images(img_right))\n",
    "# #         aug_list_of_steering_angles.append(steering_right)\n",
    "# #         flag = True\n",
    "    \n",
    "# #     #randomly shift the image and get the corresponding sheered image and adjusted steering angle \n",
    "# #     image_tr,steer_ang,tr_x = trans_image(img_center,steering_center,80)\n",
    "# #     aug_list_of_images.append(image_tr)\n",
    "# #     aug_list_of_steering_angles.append(steer)\n",
    "    \n",
    "    \n",
    "# #     #adjust the brightness for flipped image and add it to augmented list\n",
    "# #     aug_list_of_images.append(augment_brightness_camera_images(img_center_flipped))\n",
    "# #     aug_list_of_steering_angles.append(steering_center_flipped)\n",
    "\n",
    "\n",
    "\n",
    "#     #finally add to the final list \n",
    "#     car_images.extend(aug_list_of_images)\n",
    "#     steering_angles.extend(aug_list_of_steering_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#crop images to match the 66x208 nvidia architecture input\n",
    "#keras needs us to convert to numpy arrays\n",
    "# X_train = np.array(list(map(resize_img, car_images)))\n",
    "# train_samples, validation_samples, train_labels, validation_labels = train_test_split(car_images, steering_angles, test_size=0.2, random_state=42)\n",
    "\n",
    "# resized_car_images = []\n",
    "# for i in car_images:\n",
    "#     resized_car_images.append(resize_img(i))\n",
    "\n",
    "X_train = np.array(car_images)\n",
    "y_train = np.array(steering_angles)\n",
    "\n",
    "del car_images\n",
    "# del resized_car_images\n",
    "del steering_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# from sklearn.utils import shuffle\n",
    "# def generator(samples, labels, batch_size=5000):\n",
    "#     num_samples = len(samples)\n",
    "#     while 1: # Loop forever so the generator never terminates\n",
    "#         X, y = shuffle(samples, labels)\n",
    "#         for offset in range(0, num_samples, batch_size):\n",
    "#             batch_samples = X[offset:offset+batch_size]\n",
    "#             batch_labels = y[offset:offset+batch_size]\n",
    "\n",
    "#             images = []\n",
    "#             angles = []\n",
    "          \n",
    "#             for batch_sample, batch_label in zip(batch_samples, batch_labels):\n",
    "#                 images.append(resize_img(batch_sample))\n",
    "#                 angles.append(batch_label)\n",
    "\n",
    "#             # trim image to only see section with road\n",
    "#             X_train = np.array(images)\n",
    "#             y_train = np.array(angles)\n",
    "#             yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "# # compile and train the model using the generator function\n",
    "# train_generator = generator(train_samples, train_labels, batch_size=32)\n",
    "# validation_generator = generator(validation_samples, validation_labels, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmenting more data with sheering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class nvidia_model:\n",
    "    #http://www.pyimagesearch.com/2016/08/01/lenet-convolutional-neural-network-in-python/\n",
    "    @staticmethod\n",
    "    def build(width=208, height=66, depth=3):\n",
    "        \"\"\"\n",
    "        width: The width of our input images.\n",
    "        height: The height of our input images.\n",
    "        depth: The depth (i.e., number of channels) of our input images.\n",
    "        \"\"\"\n",
    "        \n",
    "        # initialize the model\n",
    "        model = Sequential()\n",
    "        #preprocessing step - 1\n",
    "        # divide by max value i.e. 255 to bring values between 0 and 1\n",
    "        #subtract 0.5 to center around 0        \n",
    "        model.add(Lambda(lambda x:x / 255 - 0.5, input_shape=(height, width, depth)))\n",
    "                          \n",
    "        #add 3 layers of conv2d , (output depth 24, 36, and 48), each with 2x2 stride\n",
    "        model.add(Conv2D(24, (5, 5), activation=\"elu\",  kernel_initializer=\"he_normal\", strides=(2,2), padding='valid'))\n",
    "        model.add(Conv2D(36, (5, 5), activation=\"elu\",  kernel_initializer=\"he_normal\", strides=(2,2), padding='valid'))\n",
    "        model.add(Conv2D(48, (5, 5), activation=\"elu\",  kernel_initializer=\"he_normal\", strides=(2,2), padding='valid'))\n",
    "        model.add(Conv2D(64, (3, 3), activation=\"elu\",  kernel_initializer=\"he_normal\", strides=(1,1), padding='valid'))\n",
    "        model.add(Conv2D(64, (3, 3), activation=\"elu\",  kernel_initializer=\"he_normal\", strides=(1,1), padding='valid'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        model.add(ELU())\n",
    "        model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "        model.add(ELU())\n",
    "        model.add(Dense(10, kernel_initializer='he_normal'))\n",
    "        model.add(ELU())\n",
    "        model.add(Dense(1, kernel_initializer='he_normal'))\n",
    "                  \n",
    "        # return the constructed network architecture\n",
    "        return model        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45001 samples, validate on 11251 samples\n",
      "Epoch 1/7\n",
      "44992/45001 [============================>.] - ETA: 0s - loss: 0.0232Epoch 00000: saving model to model-00.h5\n",
      "45001/45001 [==============================] - 500s - loss: 0.0232 - val_loss: 0.0198\n",
      "Epoch 2/7\n",
      "44992/45001 [============================>.] - ETA: 0s - loss: 0.0154Epoch 00001: saving model to model-01.h5\n",
      "45001/45001 [==============================] - 544s - loss: 0.0154 - val_loss: 0.0209\n",
      "Epoch 3/7\n",
      "44992/45001 [============================>.] - ETA: 0s - loss: 0.0133Epoch 00002: saving model to model-02.h5\n",
      "45001/45001 [==============================] - 567s - loss: 0.0133 - val_loss: 0.0192\n",
      "Epoch 4/7\n",
      "44992/45001 [============================>.] - ETA: 0s - loss: 0.0117Epoch 00003: saving model to model-03.h5\n",
      "45001/45001 [==============================] - 538s - loss: 0.0117 - val_loss: 0.0199\n",
      "Epoch 5/7\n",
      "44992/45001 [============================>.] - ETA: 0s - loss: 0.0106Epoch 00004: saving model to model-04.h5\n",
      "45001/45001 [==============================] - 509s - loss: 0.0106 - val_loss: 0.0201\n",
      "Epoch 6/7\n",
      "44992/45001 [============================>.] - ETA: 0s - loss: 0.0095Epoch 00005: saving model to model-05.h5\n",
      "45001/45001 [==============================] - 500s - loss: 0.0095 - val_loss: 0.0199\n",
      "Epoch 7/7\n",
      "44992/45001 [============================>.] - ETA: 0s - loss: 0.0088Epoch 00006: saving model to model-06.h5\n",
      "45001/45001 [==============================] - 502s - loss: 0.0088 - val_loss: 0.0192\n"
     ]
    }
   ],
   "source": [
    "model = nvidia_model.build()\n",
    "\n",
    "\n",
    "# checkpoint\n",
    "checkpoint = ModelCheckpoint(\"model-{epoch:02d}.h5\", monitor='loss', verbose=1, save_best_only=False, mode='max')\n",
    "\n",
    "# model.compile(loss='mse', optimizer='adam')\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=adam, loss='mse')    \n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=7, callbacks=[checkpoint])\n",
    "\n",
    "model.save('model_nvidia_v3.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56252, 66, 208, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56252,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# history = model.fit_generator((train_generator), steps_per_epoch = len(train_samples), epochs = 7,\n",
    "#                     verbose=1, callbacks=[checkpoint], validation_data=validation_generator, validation_steps=len(validation_samples))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
